{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575dad1a",
   "metadata": {
    "id": "575dad1a"
   },
   "source": [
    "Name: Peishan Huang Github Username: peishanhuang USC ID: 7777529178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25e6815",
   "metadata": {
    "id": "e25e6815"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af979f27",
   "metadata": {
    "id": "af979f27"
   },
   "source": [
    "(a) Download the Anuran Calls (MFCCs) Data Set from: https://archive.ics. uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29. Choose 70% of the data randomly as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1990302",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "d1990302",
    "outputId": "3737c15f-9eb8-4372-a5eb-62651037d87b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_13</th>\n",
       "      <th>MFCCs_14</th>\n",
       "      <th>MFCCs_15</th>\n",
       "      <th>MFCCs_16</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437098</td>\n",
       "      <td>0.563072</td>\n",
       "      <td>0.654825</td>\n",
       "      <td>0.388060</td>\n",
       "      <td>0.534882</td>\n",
       "      <td>-0.171721</td>\n",
       "      <td>-0.122150</td>\n",
       "      <td>0.240828</td>\n",
       "      <td>0.326598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071466</td>\n",
       "      <td>-0.344566</td>\n",
       "      <td>-0.324322</td>\n",
       "      <td>0.274203</td>\n",
       "      <td>0.192508</td>\n",
       "      <td>-0.111131</td>\n",
       "      <td>-0.186071</td>\n",
       "      <td>-0.160570</td>\n",
       "      <td>0.102977</td>\n",
       "      <td>0.208176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.072467</td>\n",
       "      <td>-0.122484</td>\n",
       "      <td>0.287449</td>\n",
       "      <td>0.364630</td>\n",
       "      <td>0.249728</td>\n",
       "      <td>0.077696</td>\n",
       "      <td>-0.235666</td>\n",
       "      <td>-0.203782</td>\n",
       "      <td>0.257359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311304</td>\n",
       "      <td>0.048169</td>\n",
       "      <td>0.202200</td>\n",
       "      <td>-0.002437</td>\n",
       "      <td>-0.112919</td>\n",
       "      <td>-0.070130</td>\n",
       "      <td>-0.074412</td>\n",
       "      <td>0.024477</td>\n",
       "      <td>0.163672</td>\n",
       "      <td>0.100309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.386418</td>\n",
       "      <td>0.379906</td>\n",
       "      <td>0.613172</td>\n",
       "      <td>0.164394</td>\n",
       "      <td>-0.017655</td>\n",
       "      <td>-0.029617</td>\n",
       "      <td>0.107008</td>\n",
       "      <td>0.268713</td>\n",
       "      <td>-0.014125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367510</td>\n",
       "      <td>-0.159391</td>\n",
       "      <td>-0.289412</td>\n",
       "      <td>0.123831</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>-0.002963</td>\n",
       "      <td>-0.084150</td>\n",
       "      <td>-0.080822</td>\n",
       "      <td>0.073412</td>\n",
       "      <td>0.168509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.595779</td>\n",
       "      <td>0.369039</td>\n",
       "      <td>0.599808</td>\n",
       "      <td>0.103479</td>\n",
       "      <td>0.062812</td>\n",
       "      <td>0.021413</td>\n",
       "      <td>0.069957</td>\n",
       "      <td>0.248353</td>\n",
       "      <td>0.087674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376688</td>\n",
       "      <td>-0.031738</td>\n",
       "      <td>-0.347424</td>\n",
       "      <td>-0.039332</td>\n",
       "      <td>0.074498</td>\n",
       "      <td>-0.032053</td>\n",
       "      <td>-0.042193</td>\n",
       "      <td>-0.131873</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.231704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.292402</td>\n",
       "      <td>0.543928</td>\n",
       "      <td>0.156354</td>\n",
       "      <td>0.083883</td>\n",
       "      <td>-0.052567</td>\n",
       "      <td>0.061893</td>\n",
       "      <td>0.273185</td>\n",
       "      <td>-0.009790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384666</td>\n",
       "      <td>-0.071980</td>\n",
       "      <td>-0.233064</td>\n",
       "      <td>0.125482</td>\n",
       "      <td>0.219086</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>-0.071318</td>\n",
       "      <td>-0.098266</td>\n",
       "      <td>0.079764</td>\n",
       "      <td>0.179122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>0.573672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903552</td>\n",
       "      <td>0.297998</td>\n",
       "      <td>-0.397597</td>\n",
       "      <td>0.025150</td>\n",
       "      <td>0.176275</td>\n",
       "      <td>-0.331872</td>\n",
       "      <td>-0.189589</td>\n",
       "      <td>0.445283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159521</td>\n",
       "      <td>0.236589</td>\n",
       "      <td>-0.171729</td>\n",
       "      <td>-0.097205</td>\n",
       "      <td>-0.007438</td>\n",
       "      <td>-0.128656</td>\n",
       "      <td>-0.159926</td>\n",
       "      <td>0.111799</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.375461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7092</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019049</td>\n",
       "      <td>0.712357</td>\n",
       "      <td>0.533261</td>\n",
       "      <td>-0.035684</td>\n",
       "      <td>-0.018522</td>\n",
       "      <td>-0.019072</td>\n",
       "      <td>0.176124</td>\n",
       "      <td>0.156899</td>\n",
       "      <td>-0.141043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015083</td>\n",
       "      <td>-0.053594</td>\n",
       "      <td>-0.033491</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.062008</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>-0.032998</td>\n",
       "      <td>0.012297</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.015541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6809</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163810</td>\n",
       "      <td>0.665300</td>\n",
       "      <td>0.384339</td>\n",
       "      <td>-0.269597</td>\n",
       "      <td>0.314491</td>\n",
       "      <td>0.325836</td>\n",
       "      <td>-0.237399</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>0.312922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306365</td>\n",
       "      <td>0.194070</td>\n",
       "      <td>-0.095146</td>\n",
       "      <td>-0.099173</td>\n",
       "      <td>0.057694</td>\n",
       "      <td>0.032423</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.083711</td>\n",
       "      <td>0.070189</td>\n",
       "      <td>-0.093839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.342927</td>\n",
       "      <td>0.365706</td>\n",
       "      <td>0.630354</td>\n",
       "      <td>0.132667</td>\n",
       "      <td>-0.063574</td>\n",
       "      <td>-0.109142</td>\n",
       "      <td>0.118062</td>\n",
       "      <td>0.345949</td>\n",
       "      <td>0.040458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396807</td>\n",
       "      <td>-0.131029</td>\n",
       "      <td>-0.305096</td>\n",
       "      <td>0.049683</td>\n",
       "      <td>0.120068</td>\n",
       "      <td>-0.061841</td>\n",
       "      <td>-0.059352</td>\n",
       "      <td>-0.072934</td>\n",
       "      <td>0.045944</td>\n",
       "      <td>0.144721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.295937</td>\n",
       "      <td>0.114834</td>\n",
       "      <td>0.588624</td>\n",
       "      <td>0.181034</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>-0.171593</td>\n",
       "      <td>0.048328</td>\n",
       "      <td>0.310919</td>\n",
       "      <td>0.102902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444663</td>\n",
       "      <td>-0.037336</td>\n",
       "      <td>-0.374471</td>\n",
       "      <td>-0.016528</td>\n",
       "      <td>0.298897</td>\n",
       "      <td>0.127061</td>\n",
       "      <td>-0.116652</td>\n",
       "      <td>-0.242900</td>\n",
       "      <td>-0.010447</td>\n",
       "      <td>0.273664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5036 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "5949  1.000000  0.437098  0.563072  0.654825  0.388060  0.534882 -0.171721   \n",
       "42    1.000000  0.072467 -0.122484  0.287449  0.364630  0.249728  0.077696   \n",
       "2610  1.000000  0.386418  0.379906  0.613172  0.164394 -0.017655 -0.029617   \n",
       "3904  1.000000  0.595779  0.369039  0.599808  0.103479  0.062812  0.021413   \n",
       "4104  1.000000  0.427451  0.292402  0.543928  0.156354  0.083883 -0.052567   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5016  0.573672  1.000000  0.903552  0.297998 -0.397597  0.025150  0.176275   \n",
       "7092  1.000000  0.019049  0.712357  0.533261 -0.035684 -0.018522 -0.019072   \n",
       "6809  1.000000  0.163810  0.665300  0.384339 -0.269597  0.314491  0.325836   \n",
       "2630  1.000000  0.342927  0.365706  0.630354  0.132667 -0.063574 -0.109142   \n",
       "1715  1.000000  0.295937  0.114834  0.588624  0.181034  0.006092 -0.171593   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_13  MFCCs_14  MFCCs_15  \\\n",
       "5949 -0.122150  0.240828  0.326598  ... -0.071466 -0.344566 -0.324322   \n",
       "42   -0.235666 -0.203782  0.257359  ... -0.311304  0.048169  0.202200   \n",
       "2610  0.107008  0.268713 -0.014125  ...  0.367510 -0.159391 -0.289412   \n",
       "3904  0.069957  0.248353  0.087674  ...  0.376688 -0.031738 -0.347424   \n",
       "4104  0.061893  0.273185 -0.009790  ...  0.384666 -0.071980 -0.233064   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5016 -0.331872 -0.189589  0.445283  ...  0.159521  0.236589 -0.171729   \n",
       "7092  0.176124  0.156899 -0.141043  ...  0.015083 -0.053594 -0.033491   \n",
       "6809 -0.237399  0.026014  0.312922  ...  0.306365  0.194070 -0.095146   \n",
       "2630  0.118062  0.345949  0.040458  ...  0.396807 -0.131029 -0.305096   \n",
       "1715  0.048328  0.310919  0.102902  ...  0.444663 -0.037336 -0.374471   \n",
       "\n",
       "      MFCCs_16  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  MFCCs_21  MFCCs_22  \n",
       "5949  0.274203  0.192508 -0.111131 -0.186071 -0.160570  0.102977  0.208176  \n",
       "42   -0.002437 -0.112919 -0.070130 -0.074412  0.024477  0.163672  0.100309  \n",
       "2610  0.123831  0.207317 -0.002963 -0.084150 -0.080822  0.073412  0.168509  \n",
       "3904 -0.039332  0.074498 -0.032053 -0.042193 -0.131873  0.011194  0.231704  \n",
       "4104  0.125482  0.219086  0.016201 -0.071318 -0.098266  0.079764  0.179122  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5016 -0.097205 -0.007438 -0.128656 -0.159926  0.111799 -0.002579 -0.375461  \n",
       "7092  0.006258  0.062008  0.012259 -0.032998  0.012297  0.008330  0.015541  \n",
       "6809 -0.099173  0.057694  0.032423  0.000026  0.083711  0.070189 -0.093839  \n",
       "2630  0.049683  0.120068 -0.061841 -0.059352 -0.072934  0.045944  0.144721  \n",
       "1715 -0.016528  0.298897  0.127061 -0.116652 -0.242900 -0.010447  0.273664  \n",
       "\n",
       "[5036 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../data/Anuran Calls (MFCCs)/Frogs_MFCCs.csv')\n",
    "X=df.iloc[:,:-4]\n",
    "y=df.iloc[:,-4:-1]\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,train_size=0.7)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ecd1e",
   "metadata": {
    "id": "e28ecd1e"
   },
   "source": [
    "(b) Each instance has three labels: Families, Genus, and Species. Each of the labels has multiple classes. We wish to solve a multi-class and multi-label problem. One of the most important approaches to multi-label classification is to train a classifier for each label (binary relevance). \n",
    "We first try this approach:\n",
    "i. Research exact match and hamming score/ loss methods for evaluating multi- label classification and use them in evaluating the classifiers in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e8568",
   "metadata": {
    "id": "d11e8568"
   },
   "source": [
    "Exact match: In multilabel classification, all the predicted set of labels should exactly match with the true set of labels. \n",
    "Hamming loss: the fraction of the wrong labels to the total number of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a33055",
   "metadata": {
    "id": "f0a33055"
   },
   "source": [
    "ii. Train a SVM for each of the labels, using Gaussian kernels and one versus all classifiers. Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation.1 You are welcome to try to solve the problem with both standardized 2 and raw attributes and report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d266db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5d266db",
    "outputId": "d81ada6e-ac2c-4d3c-a200-d4ea399b2a00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of label Family is:\n",
      "\n",
      "{'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "The hamming loss for label Family:  0.009263547938860583\n",
      "The accuracy score for label Family:  0.9907364520611394\n"
     ]
    }
   ],
   "source": [
    "param_grid=[{'kernel':['rbf'],'C':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4],'gamma':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4]}]\n",
    "svc=SVC()\n",
    "model=GridSearchCV(svc,param_grid,cv=10)\n",
    "#label='Family'\n",
    "model.fit(X_train,y_train['Family'])\n",
    "print('The best parameters of label Family is:\\n')\n",
    "print(model.best_params_)\n",
    "y_pred=model.predict(X_test)\n",
    "hammingloss=hamming_loss(y_test['Family'],y_pred)\n",
    "print('The hamming loss for label Family: ',hammingloss)\n",
    "accuracy=accuracy_score(y_test['Family'],y_pred)\n",
    "print('The accuracy score for label Family: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724c197d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "724c197d",
    "outputId": "a49cc89b-810f-46d3-ff46-84237351f40b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of label Genus is:\n",
      "\n",
      "{'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "The hamming loss for label Genus:  0.0111162575266327\n",
      "The accuracy score for label Genus:  0.9888837424733673\n"
     ]
    }
   ],
   "source": [
    "param_grid=[{'kernel':['rbf'],'C':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4],'gamma':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4]}]\n",
    "svc=SVC()\n",
    "model=GridSearchCV(svc,param_grid,cv=10)\n",
    "\n",
    "#label='Genus'\n",
    "model.fit(X_train,y_train['Genus'])\n",
    "print('The best parameters of label Genus is:\\n')\n",
    "print(model.best_params_)\n",
    "y_pred=model.predict(X_test)\n",
    "hammingloss=hamming_loss(y_test['Genus'],y_pred)\n",
    "print('The hamming loss for label Genus: ', hammingloss)\n",
    "accuracy=accuracy_score(y_test['Genus'],y_pred)\n",
    "print('The accuracy score for label Genus: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "kyTKRODjtGBZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyTKRODjtGBZ",
    "outputId": "f5332d75-c660-423b-fa86-bc82625101cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of label Species is:\n",
      "\n",
      "{'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "The hamming loss for label Species:  0.012968967114404817\n",
      "The accuracy score for label Species:  0.9870310328855951\n"
     ]
    }
   ],
   "source": [
    "param_grid=[{'kernel':['rbf'],'C':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4],'gamma':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4]}]\n",
    "svc=SVC()\n",
    "model=GridSearchCV(svc,param_grid,cv=10)\n",
    "\n",
    "#label='Species'\n",
    "model.fit(X_train,y_train['Species'])\n",
    "print('The best parameters of label Species is:\\n')\n",
    "print(model.best_params_)\n",
    "y_pred=model.predict(X_test)\n",
    "hammingloss=hamming_loss(y_test['Species'],y_pred)\n",
    "print('The hamming loss for label Species: ', hammingloss)\n",
    "accuracy=accuracy_score(y_test['Species'],y_pred)\n",
    "print('The accuracy score for label Species: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd427c",
   "metadata": {},
   "source": [
    "iii. Repeat 1(b)ii with L1-penalized SVMs. Remember to standardize4 the attributes. Determine the weight of the SVM penalty using 10 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fEbi2-HN0MWD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEbi2-HN0MWD",
    "outputId": "344fd7c8-6201-497c-f703-37fc2c33368a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of label Family is:\n",
      "\n",
      "{'C': 100.0, 'max_iter': 2000}\n",
      "The hamming loss for label Family:  0.06067623899953682\n",
      "The accuracy score for label Family:  0.9393237610004632\n"
     ]
    }
   ],
   "source": [
    "#standardize features\n",
    "scaler=StandardScaler()\n",
    "scaled_Xtrain=scaler.fit_transform(X_train)\n",
    "scaled_Xtest = scaler.transform(X_test)\n",
    "\n",
    "param_grid=[{'C':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4], 'max_iter': [2000]}]\n",
    "svc=LinearSVC(penalty='l1',dual=False)\n",
    "model=GridSearchCV(svc,param_grid,cv=10)\n",
    "\n",
    "#label='Family'\n",
    "model.fit(scaled_Xtrain,y_train['Family'])\n",
    "print('The best parameters of label Family is:\\n')\n",
    "print(model.best_params_)\n",
    "y_pred=model.predict(scaled_Xtest)\n",
    "hammingloss=hamming_loss(y_test['Family'],y_pred)\n",
    "print('The hamming loss for label Family: ', hammingloss)\n",
    "accuracy=accuracy_score(y_test['Family'],y_pred)\n",
    "print('The accuracy score for label Family: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "NM6QfRIs9G4w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NM6QfRIs9G4w",
    "outputId": "f3a526b2-dd3a-48a5-9993-4093935152dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of label Genus is:\n",
      "\n",
      "{'C': 10.0, 'max_iter': 2000}\n",
      "The hamming loss for label Genus:  0.04400185270958777\n",
      "The accuracy score for label Genus:  0.9559981472904122\n"
     ]
    }
   ],
   "source": [
    "param_grid=[{'C':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4], 'max_iter': [2000]}]\n",
    "svc=LinearSVC(penalty='l1',dual=False)\n",
    "model=GridSearchCV(svc,param_grid,cv=10)\n",
    "\n",
    "#label='Genus'\n",
    "model.fit(scaled_Xtrain,y_train['Genus'])\n",
    "print('The best parameters of label Genus is:\\n')\n",
    "print(model.best_params_)\n",
    "y_pred=model.predict(scaled_Xtest)\n",
    "hammingloss=hamming_loss(y_test['Genus'],y_pred)\n",
    "print('The hamming loss for label Genus: ', hammingloss)\n",
    "accuracy=accuracy_score(y_test['Genus'],y_pred)\n",
    "print('The accuracy score for label Genus: ', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "GkRtvQXV9sVG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GkRtvQXV9sVG",
    "outputId": "bda66f9c-7c4b-4739-c897-491867bd8800"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of label Species is:\n",
      "\n",
      "{'C': 1.0, 'max_iter': 2000}\n",
      "The hamming loss for label Species:  0.0333487725798981\n",
      "The accuracy score for label Species:  0.9666512274201019\n"
     ]
    }
   ],
   "source": [
    "param_grid=[{'C':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4], 'max_iter': [2000]}]\n",
    "svc=LinearSVC(penalty='l1',dual=False)\n",
    "model=GridSearchCV(svc,param_grid,cv=10)\n",
    "\n",
    "#label='Species'\n",
    "model.fit(scaled_Xtrain,y_train['Species'])\n",
    "print('The best parameters of label Species is:\\n')\n",
    "print(model.best_params_)\n",
    "y_pred=model.predict(scaled_Xtest)\n",
    "hammingloss=hamming_loss(y_test['Species'],y_pred)\n",
    "print('The hamming loss for label Species: ', hammingloss)\n",
    "accuracy=accuracy_score(y_test['Species'],y_pred)\n",
    "print('The accuracy score for label Species: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a60d3",
   "metadata": {},
   "source": [
    "iv. Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance. Report your conclusions about the classifiers you trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "DfqQGH_ZAMBn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfqQGH_ZAMBn",
    "outputId": "3c13ee3d-23bc-4841-a220-f31835148b89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Family           Genus          Species               \n",
       "Leptodactylidae  Adenomera      AdenomeraHylaedactylus    2429\n",
       "Hylidae          Hypsiboas      HypsiboasCordobae          780\n",
       "Leptodactylidae  Adenomera      AdenomeraAndre             470\n",
       "Dendrobatidae    Ameerega       Ameeregatrivittata         374\n",
       "Hylidae          Hypsiboas      HypsiboasCinerascens       339\n",
       "                 Dendropsophus  HylaMinuta                 223\n",
       "Leptodactylidae  Leptodactylus  LeptodactylusFuscus        190\n",
       "Hylidae          Scinax         ScinaxRuber                105\n",
       "                 Osteocephalus  OsteocephalusOophagus       80\n",
       "Bufonidae        Rhinella       Rhinellagranulosa           46\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bMZ6zrLjmB2v",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bMZ6zrLjmB2v",
    "outputId": "aa765d8e-b359-497a-dfe6-f142a7005b1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of label Family is:\n",
      "\n",
      "{'C': 1.0, 'max_iter': 2000}\n",
      "The hamming loss for label Family:  0.08244557665585919\n",
      "The accuracy score for label Family:  0.9175544233441408\n"
     ]
    }
   ],
   "source": [
    "#family label\n",
    "oversample=SMOTE()\n",
    "X_tr, y_tr= oversample.fit_resample(X_train, y_train['Family'])\n",
    "y_tr.value_counts()\n",
    "\n",
    "#standardize features\n",
    "scaler=StandardScaler()\n",
    "scaled_Xtrain=scaler.fit_transform(X_tr)\n",
    "scaled_Xtest = scaler.transform(X_test)\n",
    "\n",
    "param_grid=[{'C':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4], 'max_iter': [2000]}]\n",
    "svc=LinearSVC(penalty='l1',dual=False)\n",
    "model=GridSearchCV(svc,param_grid,cv=10)\n",
    "\n",
    "#label='Family'\n",
    "model.fit(scaled_Xtrain,y_tr)\n",
    "print('The best parameters of label Family is:\\n')\n",
    "print(model.best_params_)\n",
    "y_pred=model.predict(scaled_Xtest)\n",
    "hammingloss=hamming_loss(y_test['Family'],y_pred)\n",
    "print('The hamming loss for label Family: ', hammingloss)\n",
    "accuracy=accuracy_score(y_test['Family'],y_pred)\n",
    "print('The accuracy score for label Family: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "Wotj2tdjv_aY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wotj2tdjv_aY",
    "outputId": "283136f1-ed7f-4c6a-d01e-b3143b0e41f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of label Genus is:\n",
      "\n",
      "{'C': 100.0, 'max_iter': 3000}\n",
      "The hamming loss for label Genus:  0.08059286706808708\n",
      "The accuracy score for label Genus:  0.9194071329319129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "#genus label\n",
    "oversample=SMOTE()\n",
    "X_tr, y_tr = oversample.fit_resample(X_train,y_train['Genus'])\n",
    "y_tr.value_counts()\n",
    "\n",
    "#standardize features\n",
    "scaler=StandardScaler()\n",
    "scaled_Xtrain=scaler.fit_transform(X_tr)\n",
    "scaled_Xtest = scaler.transform(X_test)\n",
    "\n",
    "param_grid=[{'C':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4], 'max_iter': [3000]}]\n",
    "svc=LinearSVC(penalty='l1',dual=False)\n",
    "model=GridSearchCV(svc,param_grid,cv=10)\n",
    "\n",
    "#label='Genus'\n",
    "model.fit(scaled_Xtrain,y_tr)\n",
    "print('The best parameters of label Genus is:\\n')\n",
    "print(model.best_params_)\n",
    "y_pred=model.predict(scaled_Xtest)\n",
    "hammingloss=hamming_loss(y_test['Genus'],y_pred)\n",
    "print('The hamming loss for label Genus: ', hammingloss)\n",
    "accuracy=accuracy_score(y_test['Genus'],y_pred)\n",
    "print('The accuracy score for label Genus: ', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3EKeRuRD9TRI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3EKeRuRD9TRI",
    "outputId": "98eed41b-84c9-4565-804d-88dc7a5f44b0"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of label Species is:\n",
      "\n",
      "{'C': 100.0, 'max_iter': 4000}\n",
      "The hamming loss for label Species:  0.03983325613710051\n",
      "The accuracy score for label Species:  0.9601667438628995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "#species label\n",
    "oversample = SMOTE()\n",
    "X_tr, y_tr = oversample.fit_resample(X_train, y_train['Species'])\n",
    "y_tr.value_counts()\n",
    "\n",
    "#standardize features\n",
    "scaler=StandardScaler()\n",
    "scaled_Xtrain=scaler.fit_transform(X_tr)\n",
    "scaled_Xtest=scaler.transform(X_test)\n",
    "\n",
    "param_grid=[{'C':[1e-4,1e-3,1e-2,1e-1,1e-0,1e+1,1e+2,1e+3,1e+4], 'max_iter': [4000]}]\n",
    "svc=LinearSVC(penalty='l1',dual=False)\n",
    "model=GridSearchCV(svc,param_grid,cv=10)\n",
    "\n",
    "#label='Species'\n",
    "model.fit(scaled_Xtrain,y_tr)\n",
    "print('The best parameters of label Species is:\\n')\n",
    "print(model.best_params_)\n",
    "y_pred=model.predict(scaled_Xtest)\n",
    "hammingloss=hamming_loss(y_test['Species'],y_pred)\n",
    "print('The hamming loss for label Species: ', hammingloss)\n",
    "accuracy=accuracy_score(y_test['Species'],y_pred)\n",
    "print('The accuracy score for label Species: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a469ac",
   "metadata": {},
   "source": [
    "2. K-Means Clustering on a Multi-Class and Multi-Label Data Set Monte-Carlo Simulation: Perform the following procedures 50 times, and report\n",
    "the average and standard deviation of the 50 Hamming Distances that you calculate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c879dd4",
   "metadata": {},
   "source": [
    "(a) Use k-means clustering on the whole Anuran Calls (MFCCs) Data Set (do not split the data into train and test, as we are not performing supervised learning in this exercise). Choose k âˆˆ {1, 2, . . . , 50} automatically based on one of the methods provided in the slides (CH or Gap Statistics or scree plots or Silhouettes) or any other method you know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eVAkK3N1CcNg",
   "metadata": {
    "id": "eVAkK3N1CcNg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_13</th>\n",
       "      <th>MFCCs_14</th>\n",
       "      <th>MFCCs_15</th>\n",
       "      <th>MFCCs_16</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156436</td>\n",
       "      <td>0.082245</td>\n",
       "      <td>0.135752</td>\n",
       "      <td>-0.024017</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254341</td>\n",
       "      <td>0.022786</td>\n",
       "      <td>0.163320</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237384</td>\n",
       "      <td>0.050791</td>\n",
       "      <td>0.207338</td>\n",
       "      <td>0.083536</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317084</td>\n",
       "      <td>-0.011567</td>\n",
       "      <td>0.100413</td>\n",
       "      <td>-0.050224</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298524</td>\n",
       "      <td>0.037439</td>\n",
       "      <td>0.219153</td>\n",
       "      <td>0.062837</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.554504</td>\n",
       "      <td>-0.337717</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.443451</td>\n",
       "      <td>0.093889</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.081075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145668</td>\n",
       "      <td>-0.059364</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>-0.000861</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>0.071001</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>-0.021860</td>\n",
       "      <td>-0.079860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.517273</td>\n",
       "      <td>-0.370574</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.068097</td>\n",
       "      <td>0.402890</td>\n",
       "      <td>0.096628</td>\n",
       "      <td>-0.116460</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.089034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164675</td>\n",
       "      <td>-0.105600</td>\n",
       "      <td>0.030767</td>\n",
       "      <td>0.006457</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.068978</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>-0.101892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.582557</td>\n",
       "      <td>-0.343237</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.385596</td>\n",
       "      <td>0.114905</td>\n",
       "      <td>-0.103317</td>\n",
       "      <td>0.070370</td>\n",
       "      <td>0.081317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150025</td>\n",
       "      <td>-0.078615</td>\n",
       "      <td>0.024861</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>-0.009688</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>-0.080425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.519497</td>\n",
       "      <td>-0.307553</td>\n",
       "      <td>-0.004922</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.086866</td>\n",
       "      <td>-0.115799</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153120</td>\n",
       "      <td>-0.075320</td>\n",
       "      <td>0.022903</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.051796</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.041803</td>\n",
       "      <td>-0.027911</td>\n",
       "      <td>-0.096895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.508833</td>\n",
       "      <td>-0.324106</td>\n",
       "      <td>0.062068</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.397188</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>-0.117672</td>\n",
       "      <td>0.058874</td>\n",
       "      <td>0.076180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150554</td>\n",
       "      <td>-0.073415</td>\n",
       "      <td>0.042517</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.061455</td>\n",
       "      <td>0.072983</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.031560</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>-0.087910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7195 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0          1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1          1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2          1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3          1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4          1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7190       1.0 -0.554504 -0.337717  0.035533  0.034511  0.443451  0.093889   \n",
       "7191       1.0 -0.517273 -0.370574  0.030673  0.068097  0.402890  0.096628   \n",
       "7192       1.0 -0.582557 -0.343237  0.029468  0.064179  0.385596  0.114905   \n",
       "7193       1.0 -0.519497 -0.307553 -0.004922  0.072865  0.377131  0.086866   \n",
       "7194       1.0 -0.508833 -0.324106  0.062068  0.078211  0.397188  0.094596   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_13  MFCCs_14  MFCCs_15  \\\n",
       "0    -0.150063 -0.171128  0.124676  ... -0.156436  0.082245  0.135752   \n",
       "1    -0.222475 -0.207693  0.170883  ... -0.254341  0.022786  0.163320   \n",
       "2    -0.242234 -0.219153  0.232538  ... -0.237384  0.050791  0.207338   \n",
       "3    -0.194347 -0.098181  0.270375  ... -0.317084 -0.011567  0.100413   \n",
       "4    -0.265423 -0.172700  0.266434  ... -0.298524  0.037439  0.219153   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7190 -0.100753  0.037087  0.081075  ... -0.145668 -0.059364  0.024206   \n",
       "7191 -0.116460  0.063727  0.089034  ... -0.164675 -0.105600  0.030767   \n",
       "7192 -0.103317  0.070370  0.081317  ... -0.150025 -0.078615  0.024861   \n",
       "7193 -0.115799  0.056979  0.089316  ... -0.153120 -0.075320  0.022903   \n",
       "7194 -0.117672  0.058874  0.076180  ... -0.150554 -0.073415  0.042517   \n",
       "\n",
       "      MFCCs_16  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  MFCCs_21  MFCCs_22  \n",
       "0    -0.024017 -0.108351 -0.077623 -0.009568  0.057684  0.118680  0.014038  \n",
       "1     0.012022 -0.090974 -0.056510 -0.035303  0.020140  0.082263  0.029056  \n",
       "2     0.083536 -0.050691 -0.023590 -0.066722 -0.025083  0.099108  0.077162  \n",
       "3    -0.050224 -0.136009 -0.177037 -0.130498 -0.054766 -0.018691  0.023954  \n",
       "4     0.062837 -0.048885 -0.053074 -0.088550 -0.031346  0.108610  0.079244  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "7190 -0.000861  0.069430  0.071001  0.021591  0.052449 -0.021860 -0.079860  \n",
       "7191  0.006457  0.061127  0.068978  0.017745  0.046461 -0.015418 -0.101892  \n",
       "7192  0.008696  0.082474  0.077771 -0.009688  0.027834 -0.000531 -0.080425  \n",
       "7193  0.001924  0.051796  0.069073  0.017963  0.041803 -0.027911 -0.096895  \n",
       "7194  0.004158  0.061455  0.072983 -0.003980  0.031560 -0.029355 -0.087910  \n",
       "\n",
       "[7195 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('../data/Anuran Calls (MFCCs)/Frogs_MFCCs.csv')\n",
    "X=df.iloc[:,:-4]\n",
    "X\n",
    "#for i in range(50):\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a4d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Huang_Peishan_HW7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
